# Smart Placement AI âš¡

Smart Placement AI is a self-hosted resume analyzer that combines:
âœ… a lightweight similarity model + ğŸ¤– Gemini insights, with ğŸ” Google sign-in and ğŸ“œ per-user history.

## Highlights âœ¨

- ğŸ§  Resume analysis (strengths, weaknesses, ATS notes, rewrite suggestions)
- ğŸ“ˆ Match score (0â€“100) and recommended roles
- ğŸ” Google ID-token auth (verified + cached in Redis)
- ğŸ—„ï¸ PDFs stored in MinIO + viewable from the UI
- ğŸ˜ Results stored in Postgres + `/history` per account

## How It Works (1-minute mental model) ğŸ§©

1) Frontend gets a Google **ID token**
2) Backend verifies token (Google `tokeninfo`) and caches it in **Redis**
3) Upload â†’ backend extracts text, stores the PDF in **MinIO**, calls the **AI service**
4) Backend stores the result in **Postgres** and shows it in **History**

## Architecture ğŸ—ºï¸

```mermaid
flowchart LR
  U[ğŸ‘¤ User] --> F[ğŸ–¥ï¸ Frontend\nReact + Vite]
  F -->|Google Sign-In\nID token| F

  F -->|Upload PDF\nBearer token| B[ğŸ§  Backend API\nGo + Gin]
  B -->|Extract text\npdftotext| B

  B -->|Store PDF| S[(ğŸ—„ï¸ MinIO\nObject Storage)]
  B -->|Cache sessions\nGoogle tokeninfo| R[(âš¡ Redis)]
  B -->|Save results| P[(ğŸ˜ Postgres)]

  B -->|Analyze resume text| A[ğŸ¤– AI Service\nPython + Flask]
  A -->|Gemini insights +\nSimilarity score| B

  B -->|History + PDF stream| F
```

## Run (Docker) ğŸ³

Create `.env` from `.env.example`, then:

```bash
docker compose up -d --build
```

## Configuration ğŸ”§

Minimum required:

- ğŸ”‘ `GEMINI_API_KEY` (AI service)
- ğŸ˜ `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`
- ğŸ—„ï¸ `MINIO_ROOT_USER`, `MINIO_ROOT_PASSWORD`
- âš¡ `REDIS_HOST`, `REDIS_PORT` (password optional)

Google OAuth note:

- The frontend currently has a **hard-coded Google OAuth Client ID** in `frontend/src/main.tsx`.
  For a real open-source setup, replace it with your own Client ID.

## Endpoints (what youâ€™ll actually hit) ğŸ§ª

- `POST /upload` (PDF multipart form) â€” ğŸ”’ requires `Authorization: Bearer <google_id_token>`
- `GET /history` â€” ğŸ”’ requires auth
- `GET /uploads/:filename` â€” ğŸ”’ requires auth (also supports `?token=<id_token>` for inline viewing)

## Notes ğŸ“Œ

- PDF text extraction uses `pdftotext` (Poppler). The backend container installs it.
- The AI service can bootstrap a basic similarity model even without the dataset.
- Want to retrain similarity scoring? The AI service exposes `POST /train` (treat as admin-only).

## License ğŸ“„

No license file is included yet. If youâ€™re planning to publish this as OSS, add a `LICENSE` (e.g., MIT/Apache-2.0) to clarify usage rights.
